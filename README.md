# ğŸ›’ E-Commerce Customer Analytics

Pipeline de anÃ¡lisis end-to-end sobre datos de clientes de e-commerce: desde la normalizaciÃ³n de CSVs crudos hasta un modelo predictivo de churn con segmentaciÃ³n de compradores.

---

## ğŸ“‹ DescripciÃ³n del proyecto

Este proyecto construye un pipeline de datos completo que cubre las etapas fundamentales de un proyecto de analytics real:

1. **Modelado de base de datos** en esquema copo de nieve (Snowflake Schema)
2. **ETL** desde CSVs crudos de Kaggle hacia SQLite
3. **AnÃ¡lisis exploratorio** (EDA) con estadÃ­sticas descriptivas y correlaciones
4. **SegmentaciÃ³n de clientes** con K-Means (Buyer Personas)
5. **Modelo predictivo de churn** con Logistic Regression y XGBoost
6. **AnÃ¡lisis de cierre** cruzando segmentos con scores de riesgo

> **Nota sobre los datos:** Los datasets son sintÃ©ticos obtenidos de Kaggle. Los scores del modelo son excepcionalmente altos (AUC ~0.99) precisamente porque las variables fueron construidas para predecir el churn â€” algo esperado y documentado en el anÃ¡lisis.

---

## ğŸ—‚ï¸ Estructura del repositorio

```
ecommerce_db/
â”‚
â”œâ”€â”€ config.py                  # Rutas y constantes centralizadas
â”‚
â”œâ”€â”€ 01_create_schema.py        # DDL: crea tablas, Ã­ndices y vistas en SQLite
â”œâ”€â”€ 02_load_customers.py       # ETL: carga clientes (features + targets)
â”œâ”€â”€ 03_load_orders.py          # ETL: carga Ã³rdenes y dimensiones de fecha
â”œâ”€â”€ 04_validate.py             # ValidaciÃ³n de integridad referencial
â”‚
â”œâ”€â”€ 05_eda.py                  # AnÃ¡lisis exploratorio (4 secciones)
â”œâ”€â”€ 06_segmentation.py         # K-Means: segmentaciÃ³n de clientes
â”œâ”€â”€ 07_churn_model.py          # Modelos predictivos de churn
â”œâ”€â”€ 08_risk_analysis.py        # AnÃ¡lisis de cierre: segmentos Ã— riesgo
â”‚
â”œâ”€â”€ run_all.py                 # Orquestador: corre el pipeline completo
â”‚
â””â”€â”€ snowflake_schema_ddl.sql   # DDL standalone para referencia
```

---

## ğŸ—„ï¸ Esquema de base de datos

El proyecto implementa un **Snowflake Schema** con dos subject areas independientes:

```
dim_loyalty_status â”€â”€â–º fact_customers
                           (6,000 clientes Â· churn label Â· mÃ©tricas de comportamiento)

dim_date â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
dim_product_categoryâ”€â”¤
dim_payment_method â”€â”€â”¼â”€â”€â–º fact_orders
dim_order_status â”€â”€â”€â”€â”˜        (2,600 Ã³rdenes Â· valor Â· rating Â· estado)

â”€â”€ Tablas generadas por el pipeline â”€â”€
customer_segments   (K-Means: segmento asignado por cliente)
churn_scores        (score 0â€“1 Â· tier Bajo/Medio/Alto/CrÃ­tico)
```

Los dos bloques no comparten llaves â€” limitaciÃ³n conocida del dataset fuente, documentada en el anÃ¡lisis.

---

## ğŸ“Š Resultados principales

### SegmentaciÃ³n de clientes (K-Means, k=4)

| Segmento | Clientes | Churn rate | Perfil |
|---|---|---|---|
| ğŸ’ Cliente Premium | 1,845 (30.8%) | 0.2% | Alto valor, alta frecuencia, muy comprometido |
| ğŸ·ï¸ Cazador de Ofertas | 1,928 (32.1%) | 1.1% | Compra por descuento, baja lealtad intrÃ­nseca |
| ğŸŒŸ Cliente Leal | 1,362 (22.7%) | 14.4% | Buen engagement, en zona intermedia de riesgo |
| âš ï¸ Cliente en Riesgo | 865 (14.4%) | 82.0% | Alta inactividad, prÃ¡cticamente perdidos |

### Modelo predictivo de churn

| Modelo | Accuracy | Recall | F1 | ROC-AUC |
|---|---|---|---|---|
| Logistic Regression | 0.9608 | **0.9247** | 0.8798 | **0.9931** |
| XGBoost | 0.9592 | 0.9032 | 0.8727 | 0.9925 |

**Ganador: Logistic Regression** â€” mejor recall y AUC. En churn prediction el recall es la mÃ©trica crÃ­tica: minimizar los falsos negativos (clientes que se van sin ser detectados).

**Variables mÃ¡s importantes:** `days_since_last_purchase` (+305% diferencia entre grupos) y `engagement_score` (5.35 activos vs 2.36 churned).

### AnÃ¡lisis de cierre: CrÃ­ticos por segmento

| Segmento | CrÃ­ticos | % del segmento | AcciÃ³n recomendada |
|---|---|---|---|
| âš ï¸ Cliente en Riesgo | 703 | 81.3% | Ya perdidos â€” bajo ROI de intervenciÃ³n |
| ğŸŒŸ Cliente Leal | 179 | 13.1% | **Prioridad de retenciÃ³n** |
| ğŸ·ï¸ Cazador de Ofertas | 11 | 0.6% | Reactivar con oferta puntual |
| ğŸ’ Cliente Premium | 1 | 0.1% | Sin acciÃ³n necesaria |

> Los **179 Clientes Leales en riesgo crÃ­tico** son el target real de retenciÃ³n â€” tienen historial de valor y todavÃ­a son recuperables.

---

## âš™ï¸ InstalaciÃ³n y uso

### Requisitos

- Python 3.10+
- Las librerÃ­as del proyecto (ver abajo)

### 1. Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/ecommerce-customer-analytics.git
cd ecommerce-customer-analytics
```

### 2. Crear entorno virtual e instalar dependencias

```bash
python -m venv .venv

# Windows
.venv\Scripts\activate

# Mac/Linux
source .venv/bin/activate

pip install -r requirements.txt
```

### 3. Configurar rutas de los CSVs

Edita `config.py` y ajusta las rutas a los archivos fuente:

```python
CSV_FEATURES = Path("ruta/a/ecommerce_customer_features.csv")
CSV_TARGETS  = Path("ruta/a/ecommerce_customer_targets.csv")
CSV_ORDERS   = Path("ruta/a/daily_ecommerce_orders.csv")
```

> âš ï¸ En Windows usa barras hacia adelante (`/`) o raw strings (`r"C:\ruta\..."`) para evitar errores de encoding.

### 4. Correr el pipeline

**OpciÃ³n A â€” Script por script (recomendado la primera vez):**

```bash
python 01_create_schema.py   # Crea el esquema en SQLite
python 02_load_customers.py  # Carga clientes
python 03_load_orders.py     # Carga Ã³rdenes
python 04_validate.py        # Valida integridad

python 05_eda.py             # AnÃ¡lisis exploratorio
python 06_segmentation.py    # SegmentaciÃ³n K-Means
python 07_churn_model.py     # Modelo de churn
python 08_risk_analysis.py   # AnÃ¡lisis de cierre
```

**OpciÃ³n B â€” Pipeline completo de una vez:**

```bash
python run_all.py
```

---

## ğŸ“¦ Dependencias

```
pandas
matplotlib
seaborn
scikit-learn
xgboost
imbalanced-learn
```

Instala todo con:

```bash
pip install pandas matplotlib seaborn scikit-learn xgboost imbalanced-learn
```

---

## ğŸ” Decisiones tÃ©cnicas destacadas

**Â¿Por quÃ© Snowflake Schema y no Star Schema?**
Las dimensiones categÃ³ricas de Ã³rdenes (categorÃ­a, mÃ©todo de pago, estado) tienen pocos valores Ãºnicos pero se normalizaron igual para demostrar el patrÃ³n completo. En producciÃ³n con dimensiones mÃ¡s grandes la diferencia de performance serÃ­a significativa.

**Â¿Por quÃ© SMOTE?**
El dataset tiene desbalance de clases (84.5% activos vs 15.5% churned). Sin balanceo, un modelo que prediga siempre "activo" alcanza 84.5% de accuracy trivialmente. SMOTE genera ejemplos sintÃ©ticos de la clase minoritaria solo en el set de entrenamiento.

**Â¿Por quÃ© k=4 si el silhouette score Ã³ptimo es k=2?**
Los datos sintÃ©ticos no tienen clusters naturalmente separados (silhouette mÃ¡ximo: 0.1759). Se forzÃ³ k=4 por valor narrativo del portafolio, documentando explÃ­citamente la decisiÃ³n â€” exactamente lo que se harÃ­a en un contexto profesional cuando el negocio requiere segmentos accionables.

**Â¿Por quÃ© ganÃ³ Logistic Regression sobre XGBoost?**
En datasets con separaciÃ³n lineal clara entre clases, LR es difÃ­cil de superar. XGBoost aÃ±ade complejidad que no siempre se traduce en mejora cuando el patrÃ³n subyacente es relativamente simple.

---

## ğŸ“ Datos fuente

Los CSVs utilizados provienen de Kaggle y no se incluyen en este repositorio por tamaÃ±o. Puedes encontrarlos buscando:

- `ecommerce customer churn dataset` â€” para los archivos de clientes
- `daily ecommerce orders dataset` â€” para el archivo de Ã³rdenes

---

## ğŸ‘¤ Autor

**[Tu nombre]**
[LinkedIn] Â· [Correo]
